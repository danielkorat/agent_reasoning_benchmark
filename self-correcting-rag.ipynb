{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "5506fedd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# pip install -U transformers[agents] jupyter ipywidgets\n",
                "# pip install -U langchain-community==0.2.1 langchain-core==0.2.1 sentence-transformers faiss-cpu"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "b749a0df-a3df-40ed-a6cd-cd2b35d636d4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['datasets', 'hf-endpoints-documentation', 'hub-docs', 'course', 'evaluate', 'deep-rl-class', 'diffusers', 'transformers', 'pytorch-image-models', 'datasets-server', 'gradio', 'optimum', 'peft', 'blog']\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/root/anaconda3/envs/agents/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "import datasets\n",
                "from langchain.docstore.document import Document\n",
                "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "from langchain.vectorstores import FAISS\n",
                "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
                "\n",
                "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")\n",
                "\n",
                "source_docs = [\n",
                "    Document(\n",
                "        page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]}\n",
                "    ) for doc in knowledge_base\n",
                "]\n",
                "docs_processed = RecursiveCharacterTextSplitter(chunk_size=500).split_documents(source_docs)[:1000]\n",
                "\n",
                "all_sources = list(set([doc.metadata[\"source\"] for doc in docs_processed]))\n",
                "print(all_sources)\n",
                "\n",
                "\n",
                "embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
                "vectordb = FAISS.from_documents(\n",
                "    documents=docs_processed,\n",
                "    embedding=embedding_model\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "a3e46c2c-7aa8-473b-a0b5-8894e325e59a",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "from transformers.agents import Tool\n",
                "from langchain_core.vectorstores import VectorStore\n",
                "\n",
                "class RetrieverTool(Tool):\n",
                "    name = \"retriever\"\n",
                "    description = \"Retrieves some documents from the knowledge base that have the closest embeddings to the input query.\"\n",
                "    inputs = {\n",
                "        \"query\": {\n",
                "            \"type\": \"text\",\n",
                "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
                "        },\n",
                "        \"source\": {\n",
                "            \"type\": \"text\", \n",
                "            \"description\": \"\"\n",
                "        },\n",
                "    }\n",
                "    output_type = \"text\"\n",
                "    \n",
                "    def __init__(self, vectordb: VectorStore, all_sources: str, **kwargs):\n",
                "        super().__init__(**kwargs)\n",
                "        self.vectordb = vectordb\n",
                "        self.inputs[\"source\"][\"description\"] = (\n",
                "            f\"The source of the documents to search, as a str representation of a list. Possible values in the list are: {all_sources}. If this argument is not provided, all sources will be searched.\"\n",
                "          )\n",
                "\n",
                "    def forward(self, query: str, source: str = None) -> str:\n",
                "        assert isinstance(query, str), \"Your search query must be a string\"\n",
                "\n",
                "        if source:\n",
                "            if isinstance(source, str) and \"[\" not in str(source): # if the source is not representing a list\n",
                "                source = [source]\n",
                "            source = json.loads(str(source).replace(\"'\", '\"'))\n",
                "\n",
                "        docs = self.vectordb.similarity_search(query, filter=({\"source\": source} if source else None), k=3)\n",
                "\n",
                "        if len(docs) == 0:\n",
                "            return \"No documents found with this filtering. Try removing the source filter.\"\n",
                "        return \"Retrieved documents:\\n\\n\" + \"\\n===Document===\\n\".join(\n",
                "            [doc.page_content for doc in docs]\n",
                "        )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "3f895edd-137f-46b3-96a7-444c5c7d8d2a",
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers.agents import ReactJsonAgent, HfEngine\n",
                "\n",
                "agent = ReactJsonAgent(\n",
                "    tools=[RetrieverTool(vectordb, all_sources)],\n",
                "    llm_engine=HfEngine(\"http://127.0.0.1:8087\")\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "4e7e0141",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[33;1m======== New task ========\u001b[0m\n",
                        "\u001b[37;1mPlease show me a LORA finetuning script\u001b[0m\n",
                        "\u001b[33;1mCalling tool: 'retriever' with arguments: {'query': 'LORA finetuning script', 'source': \"['transformers', 'hf-endpoints-documentation']\"}\u001b[0m\n",
                        "\u001b[33;1mCalling tool: 'retriever' with arguments: {'query': 'LORA finetuning script'}\u001b[0m\n",
                        "\u001b[33;1mCalling tool: 'final_answer' with arguments: {'answer': 'https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/text_to_image_lora.py'}\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Final output:\n",
                        "https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/text_to_image_lora.py\n"
                    ]
                }
            ],
            "source": [
                "agent_output = agent.run(\"Please show me a LORA finetuning script\")\n",
                "print(f\"Final output:\\n{agent_output}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}